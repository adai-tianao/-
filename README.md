# 前言
本人目前就读于北京航空航天大学
因后续读博士需要学习相关的神经网络算法，但其实本人方向是同态加密等隐私计算硬件实现应用
考虑到可能进行交叉结合，特此重新将经典神经网络算法进行学习：CNN GNN Transformer
主要目的是入门加学习基础知识，不做深入学习
计划分四部分进行学习：
1. 神经网络入门及MLP(多层感知机)实现
2. CNN(卷积神经网络)入门及LeNet实现手写字体识别
3. GNN入门（基础概念，简单实现）
4. Transformer（基础概念，简单实现）
本内容算作一个学习笔记，会把一些学习过程中的问题写在上面记录
# ChatGpt辅助学习（gpt3.5）
chatgpt可以生成代码，虽然3.5仍然有较高的错误率，但是4.0自己这个学生暂时买不起，而且能纠错就还可以用
暂时就这样

--------------------------------------分割-2024.1----------------------------------------

# 1. 神经网络入门及MLP实现
问：怎么理解神经网络
答：神经网络是一种模拟人脑神经元之间相互连接的数学模型。它由多个神经元组成，这些神经元通过权重连接在一起，形成不同层次的网络结构。每个神经元接收输入，对输入进行加权求和并通过激活函数进行处理，然后将结果传递给下一层的神经元。
以下是我对神经网络的理解的一些关键要点：
1. 神经元和层次结构： 神经网络包含输入层、隐藏层和输出层。输入层接收原始数据，隐藏层对数据进行特征提取和表示学习，输出层产生最终的预测结果。
2. 权重和连接： 神经网络中的每个连接都有一个权重，这个权重决定了输入对输出的影响程度。训练神经网络的目标之一是优化这些权重，使网络能够更好地拟合训练数据。
3. 激活函数： 激活函数引入了非线性性质，使神经网络能够学习复杂的关系和模式。常见的激活函数包括ReLU（Rectified Linear Unit）、Sigmoid和TanH等。
4. 前向传播： 数据从输入层通过网络传递到输出层的过程称为前向传播。在这个过程中，每个神经元根据权重和激活函数计算输出。
5. 反向传播： 反向传播是通过计算损失函数的梯度，从输出层向输入层更新权重的过程。这是训练神经网络的关键步骤。
6. 损失函数： 损失函数衡量了神经网络的预测与真实标签之间的差异。通过最小化损失函数，神经网络可以学习提高预测准确性的特征和权重。
7. 优化算法： 优化算法用于更新神经网络的权重，以最小化损失函数。常见的优化算法包括梯度下降、Adam、RMSprop等。
8. 深度学习： 当神经网络包含多个隐藏层时，被称为深度神经网络。深度学习旨在通过层次化的特征学习来解决复杂的任务。

评：第一条是多层感知机的模型概念，其实神经网络发展到现在这个阶段，已经出现了很多网络架构如CNN，并不能简单用输入、隐藏、输出层概括。
补充：神经网络的学习过程也叫做训练，执行过程也叫做推理；
一般神经网络的训练过程包含前向传播与反向传播及权重更新，推理过程只包括前向传播；
其实神经网络算法可以看做一个超级无敌优化算法，在参数足够多、计算能力足够强的情况下，你只需要给它一组足够多的训练数据，模型就可以通过优化进行拟合真实模型，直到达到足够高的推理正确率。

因此本节以梯度下降算法作为优化算法，实现一个三层MLP，细节：

包括训练与推理过程

采用均方误差作为损失函数

E = (1/2)sigma(真实值 - 预测值)^2



